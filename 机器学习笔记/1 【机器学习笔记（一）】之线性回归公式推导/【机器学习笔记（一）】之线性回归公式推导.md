## 本文章由公号【开发小鸽】发布！欢迎关注！！！
<br>

**老规矩--妹妹镇楼：**
<center>
<img src="https://img-blog.csdnimg.cn/20200721223424816.JPG"   width="20%">

## 一. 线性回归
 &nbsp;  &nbsp;  &nbsp;  &nbsp;举例：以**年龄和工资**为参数，预测可以从银行贷款的金额。假设**θ~1~是年龄的参数，θ~2~是工资的参数**。通过提供的年龄和工资参数，对**贷款额度进行预测**。x是输入的年龄和工资值，通过**线性回归**来拟合平面。
$$ h_{\theta }(x) = \theta_{0} + \theta_{1}x_{1}+ \theta_{2}x_{2}(\theta_{0}是偏置项)$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;可以看到，上式中存在着**偏置项**，它与另外两项的格式不太相符，为了便于之后的矩阵运算，我们可以将偏置项对应的x值全都设为1，这样，三项的格式就统一了，也方便于后面矩阵的计算。
$$ h_{\theta}(x) = \sum_{i=0}^{n}\theta_{i}x_{i} = \theta^{T}x$$

## 二. 误差
 &nbsp;  &nbsp;  &nbsp;  &nbsp;真实值和预测值之间肯定是存在着**差异**的。误差如下：
$$ 对于每个样本：y^{(i)} = \theta^{T}x^{(i)} + \varepsilon ^{(i)}$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;误差是独立并且具有相同的分布，并且服从**高斯分布**。
 &nbsp;  &nbsp;  &nbsp;  &nbsp;以下式子是误差的高斯分布概率：
$$p(\varepsilon ^{(i)}) = \frac{1}{\sqrt{2\pi}\sigma }exp(-\frac{(\epsilon ^{(i)})^{2}}{2\sigma ^{2}})$$
 &nbsp;  &nbsp;  &nbsp;  &nbsp;**思考**：我们的需求是提供年龄和工资的值，系统将我们可以贷款的金额预测出来。而要实现这一过程，需要地就是年龄和工资的参数值θ，这是我们要求的参数。**而如何将上式与θ联系起来呢**？将预测值与误差的式子（下式）左右相减代入误差的高斯分布式子中，便可以得到θ相关的式子：
$$ y^{(i)} = \theta^{T}x^{(i)} + \varepsilon ^{(i)}$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;将上式代入高斯分布概率式子可以得到以下式子：
$$ p(y^{(i)}|x^{(i)};\theta) = \frac{1}{\sqrt{2\pi}\sigma }exp(-\frac{(y^{(i)} - \theta^{T}x^{(i)})^2}{2\sigma ^{2}})$$


## 三. 似然函数
 &nbsp;  &nbsp;  &nbsp;  &nbsp;得到上式后，我们就要思考我们想要获得的结果是对y值的准测估计，即预测值与真实值越接近越好，而这需要的是对参数的求解。**即什么样的参数和数据组合才能更加接近真实的输出**？这时，我们就想到了**似然函数**。似然函数，做的就是这样一类事情，通过数据样本来推导出什么样的参数能够预测出真实值。
$$ L(\theta) = \prod_{i=1}^{m}p(y^{(i)}|x^{(i)};\theta) = \prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma }exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^{2}}{2\sigma ^{2}})$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;上式即是θ参数的似然函数，由于误差是服从高斯分布的，分布在真实值的两边，**那么误差的p值越大，误差就越趋近于0，即预测值与真实值的差距越小**。这是我们所希望得到的结果，**因此似然函数中p值的连乘当然是越大越好，即极大似然估计**。
### (一). 如何求解极大似然估计呢？
#### 1. 先求对数
 &nbsp;  &nbsp;  &nbsp;  &nbsp;由于似然函数中都是连乘，很难计算，想到求对数后式子变为加法运算更加简单。
$$ logL(\theta) = log\prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma }exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^{2}}{2\sigma ^{2}})$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;展开**化简**后的式子如下：
$$ \sum_{i=1}^{m}log\frac{1}{\sqrt{2\pi}\sigma }exp(-\frac{(y^{(i)} - \theta^{T}x^{(i)})^{2}}{2\sigma ^{2}}) = mlog\frac{1}{\sqrt{2\pi}\sigma } - \frac{1}{\sigma ^{2}}\cdot \frac{1}{2}\sum_{i=1}^{m}(y^{(i)} - \theta^{T}x^{(i)})^{2}$$

#### 2. 我们的目标时让似然函数的值越大越好
 &nbsp;  &nbsp;  &nbsp;  &nbsp;从上式可以看出，前面一段是常数，因此只要后面一段的值越小越好。可以从后一段式子看出，除去常数值，可以简化为下式：
$$ J(\theta) = \frac{1}{2}\sum_{i=1}^{m}(y^{(i)} - 
\theta^{T}x^{(i)})^{2}$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;这个式子可以用**最小二乘法**来求解。
首先，将平方项的求和转换为矩阵的乘积，即矩阵的转置乘以矩阵自身，平方项即误差值。
$$ \frac{1}{2}(X\theta - y)^{T}(X\theta -  y)$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;然后将矩阵的转置展开

$$ \frac{1}{2}(\theta^{T}X^{T} - y^{T})(X\theta - y)$$ 
 &nbsp;  &nbsp;  &nbsp;  &nbsp;将两个乘式展开，
$$ \frac{1}{2}(\theta^{T}X^{T}X\theta - \theta^{T}X^{T}y - y^{T}X\theta + y^{T}y)$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;要想求式子的最小值，一般是求式子的**极值点**，参数为θ，因此对θ求**偏导**。

$$ \frac{1}{2}(2X^{T}X\theta - X^{T}y - (y^{T}X)^{T}) = X^{T}X\theta - X^{T}y$$
 &nbsp;  &nbsp;  &nbsp;  &nbsp;偏导等于0，可求出θ的值为
$$ \theta = (X^{T}X)^{-1}X^{T}y$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;至此，θ这个参数的值已被求出，线性回归的式子也因此求出。这就是去**求解线性回归参数的全过程**。
不过，求得参数后我们需要**对线性回归的效果进行评估**，最常用的评估方法如下：
$$ R^{2}:1- \frac{\sum_{i=1}^{m}(\hat{y_{i}} - y_{i})^{2}(残差平方和)}{\sum_{i=1}^{m}(y_{i} - \bar{y})^{2}(类似方差项)}$$

 &nbsp;  &nbsp;  &nbsp;  &nbsp;上式右边的**分子为预测值与真实值的差距的平方和**，**分母为真实值与平均值的差距的平方和**，所以上式评估的取值越接近于1，可以认为模型拟合效果越好。


